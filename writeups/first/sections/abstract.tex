\begin{abstract}

The engineering of an appropriate state space representation is one of the
essential prerequisites to the use of reinforcement learning (RL) in a new
domain. Constructing a successful representation, however, is often difficult
and requires an understanding of the peculiarities of a given domain. Recent
work of \citet{Mahadevan2006Value}, among others, has applied techniques from
spectral graph theory to the problem of automatically discovering or augmenting
state representations, but only to small and amenable domains. This first
submission works toward extending those techniques to tackle larger, more
challenging domains. It considers three related problems: \emph{applying}
spectral methods to the unusual tree-like state graphs of board games,
\emph{adapting} these methods to acquire state information from sampled human
gameplay, and \emph{scaling} them to combinatorial state spaces. The simple
game of Tic-Tac-Toe is used here for small-scale exploration, to prepare for a
much larger domain, the classic game of Go, in future work.

\end{abstract}

